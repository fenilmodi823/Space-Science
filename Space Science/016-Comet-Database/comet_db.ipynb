{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standard modules\n",
    "import datetime\n",
    "import pathlib\n",
    "import sqlite3\n",
    "\n",
    "# Import installed modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spiceypy\n",
    "\n",
    "# Import the Python script func from the auxiliary folder\n",
    "import sys\n",
    "sys.path.insert(1, '../auxiliary')\n",
    "import data_fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a local download path and the URL to the comet data from the Minor\n",
    "# Planet Center\n",
    "DL_PATH = 'raw_data/'\n",
    "DL_URL = 'https://www.minorplanetcenter.net/Extended_Files/cometels.json.gz'\n",
    "\n",
    "# Download the comet data and store them in the directory\n",
    "data_fetch.download_file(DL_PATH, DL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Kernels Loaded: 2\n"
     ]
    }
   ],
   "source": [
    "# Clear any previously loaded kernels\n",
    "spiceypy.kclear()\n",
    "\n",
    "# Load the SPICE kernel meta file\n",
    "kernels = [\n",
    "    '../kernels/pck/gm_de431.tpc',\n",
    "    '../kernels/lsk/naif0012.tls'\n",
    "]\n",
    "\n",
    "for kernel in kernels:\n",
    "    spiceypy.furnsh(kernel)\n",
    "\n",
    "print(\"Total Kernels Loaded:\", spiceypy.ktotal(\"ALL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the g-zipped json file with pandas read_json. The function allows one\n",
    "# to read compressed data\n",
    "c_df = pd.read_json('raw_data/cometels.json.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we parse the date and time information. The dataset contains two\n",
    "# time related information: the date-time of the last perihelion passage and\n",
    "# another variable called Epoch. However, \"epoch\" is not related to the mean\n",
    "# anomaly related epoch and represents other time information in this case.\n",
    "#\n",
    "# For our \"actual\" Epoch case we need to create a UTC time string based on the\n",
    "# date and time of the last perihelion passage (the time corresponds to a mean\n",
    "# anomaly of 0 degrees). The Day is given in DAY.FRACTION_OF_DAY. We extract\n",
    "# only the day\n",
    "c_df.loc[:, 'EPOCH_UTC_DATE'] = \\\n",
    "    c_df.apply(lambda x: str(x['Year_of_perihelion']) + '-' \\\n",
    "                         + str(x['Month_of_perihelion']) + '-' \\\n",
    "                         + str(x['Day_of_perihelion']).split('.')[0], \\\n",
    "               axis=1)\n",
    "\n",
    "# Now we need to parse the .FRACTION_OF_DAY given between (0.0, 1.0). First,\n",
    "# create a place-holder date\n",
    "pre_time = datetime.datetime(year=2000, month=1, day=1)\n",
    "\n",
    "# Use the pre_time date-time object and add the days and fraction of days with\n",
    "# the timedelta function from the datetime library. Extract only the time\n",
    "# substring ...\n",
    "c_df.loc[:, 'EPOCH_UTC_TIME'] = c_df['Day_of_perihelion'] \\\n",
    "                                    .apply(lambda x: (pre_time + datetime.timedelta(days=x)) \\\n",
    "                                                     .strftime('%H:%M:%S'))\n",
    "\n",
    "# ... and based with the date, create now the UTC date-time\n",
    "c_df.loc[:, 'EPOCH_UTC'] = c_df.apply(lambda x: x['EPOCH_UTC_DATE'] + 'T' + x['EPOCH_UTC_TIME'],\\\n",
    "                                      axis=1)\n",
    "\n",
    "# Convert the UTC datetime to ET\n",
    "c_df.loc[:, 'EPOCH_ET'] = c_df['EPOCH_UTC'].apply(lambda x: spiceypy.utc2et(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the semi-major axis for closed orbits ...\n",
    "c_df.loc[:, 'SEMI_MAJOR_AXIS_AU'] = \\\n",
    "    c_df.apply(lambda x: x['Perihelion_dist'] / (1.0 - x['e']) if x['e'] < 1 else np.nan, axis=1)\n",
    "\n",
    "# ... as well as the aphelion (if applicable)\n",
    "c_df.loc[:, 'APHELION_AU'] = c_df.apply(lambda x: (1.0 + x['e']) * x['SEMI_MAJOR_AXIS_AU'] \\\n",
    "                                                  if x['e'] < 1 else np.nan, \\\n",
    "                                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1dcd22e38c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sub-directory in the main directory of this repository, where a\n",
    "# comet database shall be stored\n",
    "pathlib.Path('../databases/comets/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create / Connect to a comet database and set the cursor\n",
    "con = sqlite3.connect('../databases/comets/mpc_comets.db')\n",
    "cur = con.cursor()\n",
    "\n",
    "# Create (if not existing) a comets' main table, where miscellaneous\n",
    "# parameters are stored\n",
    "cur.execute('CREATE TABLE IF NOT EXISTS ' \\\n",
    "            'comets_main(NAME TEXT PRIMARY KEY, ' \\\n",
    "                        'ORBIT_TYPE TEXT, ' \\\n",
    "                        'PERIHELION_AU REAL, ' \\\n",
    "                        'SEMI_MAJOR_AXIS_AU REAL, ' \\\n",
    "                        'APHELION_AU REAL, ' \\\n",
    "                        'ECCENTRICITY REAL, ' \\\n",
    "                        'INCLINATION_DEG REAL, ' \\\n",
    "                        'ARG_OF_PERIH_DEG REAL, ' \\\n",
    "                        'LONG_OF_ASC_NODE_DEG REAL, ' \\\n",
    "                        'MEAN_ANOMALY_DEG REAL DEFAULT 0.0, ' \\\n",
    "                        'EPOCH_UTC TEXT, ' \\\n",
    "                        'EPOCH_ET REAL, ' \\\n",
    "                        'ABSOLUTE_MAGNITUDE REAL, ' \\\n",
    "                        'SLOPE_PARAMETER REAL'\n",
    "                        ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data\n",
    "cur.executemany('INSERT OR REPLACE INTO ' \\\n",
    "                'comets_main(NAME, ' \\\n",
    "                            'ORBIT_TYPE, ' \\\n",
    "                            'PERIHELION_AU, ' \\\n",
    "                            'SEMI_MAJOR_AXIS_AU, ' \\\n",
    "                            'APHELION_AU, ' \\\n",
    "                            'ECCENTRICITY, ' \\\n",
    "                            'INCLINATION_DEG, ' \\\n",
    "                            'ARG_OF_PERIH_DEG, ' \\\n",
    "                            'LONG_OF_ASC_NODE_DEG, ' \\\n",
    "                            'EPOCH_UTC, ' \\\n",
    "                            'EPOCH_ET, ' \\\n",
    "                            'ABSOLUTE_MAGNITUDE, ' \\\n",
    "                            'SLOPE_PARAMETER'\n",
    "                            ') ' \\\n",
    "                'VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                c_df[['Designation_and_name', \\\n",
    "                      'Orbit_type', \\\n",
    "                      'Perihelion_dist', \\\n",
    "                      'SEMI_MAJOR_AXIS_AU', \\\n",
    "                      'APHELION_AU', \\\n",
    "                      'e', \\\n",
    "                      'i', \\\n",
    "                      'Peri', \\\n",
    "                      'Node', \\\n",
    "                      'EPOCH_UTC', \\\n",
    "                      'EPOCH_ET', \\\n",
    "                      'H', \\\n",
    "                      'G']].values)\n",
    "\n",
    "# Commit\n",
    "con.commit()\n",
    "\n",
    "# Close the database. The database shall be the fundament for the next\n",
    "# tutorial sessions\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
